# -*- coding: utf-8 -*-
"""phonepe.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nVzakSi6Db41VuSriMGCirj4f0ZNRdZY
"""

pip install GitPython

!git clone https://github.com/PhonePe/pulse.git

import csv
import subprocess
import pandas as pd
import requests
import git
import json
import os
from git import Repo
import os
import pandas as pd
import numpy as np

os.system("git clone https://github.com/phonepe/pulse.git")

"""# ***#Aggregated transcations ***

1.root_dir = (r'/content/pulse/data'): This line defines the root directory path where the data is located. The r before the string denotes a raw string, which is useful for file paths to prevent the backslashes from being treated as escape character

2.for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/aggregated/user/country/india/state')):: The code starts a loop to iterate through the items in the state directory of the given root_dir. os.listdir() function returns a list of the names of the entries in the directory path provided. The os.path.join() function is used to concatenate the root directory path with the path to the state directory.

3.state_path = os.path.join(root_dir, '/content/pulse/data/aggregated/user/country/india/state', state_dir): The variable state_path is assigned the complete path to the current state directory. state_dir contains the name of the current state folder.

4.os.path.join=os.path.join() is a function in Python's built-in os.path module. It is used to concatenate different parts of a file path into a single valid path.

5.On Google Colab, '/content/' is the root directory, and you can directly access the specified path as it is

6.The with statement automatically takes care of opening and closing the file. It guarantees that the file will be closed correctly after the block of code inside the with statement finishes execution. This helps avoid resource leaks and ensures proper handling of file-related resources

7.the file is loaded using json.load(f). This reads the JSON data from the file and parses it into a Python data structure. The result is stored in the variable data

An aggregate transaction typically refers to a single transaction that combines multiple individual transactions into one consolidated transaction. This process is commonly used in financial or payment systems to streamline and simplify the processing of multiple smaller transactions, making it more efficient for both the user and the service provider.

In the context of mobile payment platforms like PhonePe, an aggregate transaction could involve combining several smaller payments made by a user into a single transaction.
"""

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list = []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/aggregated/transaction/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/aggregated/transaction/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)

                            # Extract the data we're interested in
                            for transaction_data in data['data']['transactionData']:
                                # print(transaction_data)
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'Transaction_Type': transaction_data['name'],
                                    'Transaction_Count': transaction_data['paymentInstruments'][0]['count'],
                                    'Transaction_Amount': transaction_data['paymentInstruments'][0]['amount']
                                }
                                data_list.append(row_dict)

# Convert list of dictionaries to dataframe
df1 = pd.DataFrame(data_list)
df1

# Save the DataFrame to a CSV file named 'data.csv' in the current working directory
df1.to_csv('Aggregated transcations .csv', index=False)

"""# **#Aggregated users**

In general, the word "aggregate" refers to the total or combined sum of individual items or elements. When applied to users, it could imply the total number of users or customers considered as a whole, without distinguishing individual user details. This kind of aggregation is often used for statistical or analytical purposes to gain insights into the overall user base without compromising individual privacy.
"""

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list2= []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/aggregated/user/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/aggregated/user/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)
                            # data_list2.append(data)
                            try:
                              for g in data['data']['usersByDevice']:
                                # print(g)
                                row_dict = {
                                    'States': state_dir,
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                    'brand': g['brand'],
                                    'Transaction_Count':g['count'],
                                    'percentage': g['percentage']
                                    }
                                data_list2.append(row_dict)

                            except:
                              pass


df2=pd.DataFrame(data_list2)
df2

df2.to_csv('Aggregate users .csv', index=False)

"""#Map **transcation**"""

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list3= []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/map/transaction/hover/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/map/transaction/hover/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)
                            # data_list3.append(data)
                            try:
                              for g in data['data']['hoverDataList']:
                                # print(g)
                                row_dict = {
                                    'States': state_dir,
                                    'district':g['name'],
                                    'count':g['metric'][0]['count'],
                                    'amount':g['metric'][0]['amount'],
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                            #         'brand': g['brand'],
                            #         'Transaction_Count':g['count'],
                            #         'percentage': g['percentage']
                                    }
                                data_list3.append(row_dict)

                            except:
                              pass


df3=pd.DataFrame(data_list3)
df3

df3.to_csv('Map transcations .csv', index=False)

"""#Map **user**"""

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list4= []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/map/user/hover/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/map/user/hover/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)
                            # data_list4.append(data)
                            try:
                              for g in data['data']['hoverData']:
                                # print(g)
                                row_dict = {
                                    'States': state_dir,
                                    'district':g,
                                    'registered_users':data['data']['hoverData'][g]['registeredUsers'],
                                    'app_open':data['data']['hoverData'][g]['appOpens'],
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                   }
                                data_list4.append(row_dict)

                            except:
                              pass


df4=pd.DataFrame(data_list4)
df4

df4.to_csv('Map users .csv', index=False)

"""#Top transaction data district wise"""

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list5= []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)
                            # data_list5.append(data)
                            try:
                              for g in data['data']['districts']:
                                # print(g)
                                row_dict = {
                                    'States': state_dir,
                                    'district':g['entityName'],
                                    'count':g['metric']['count'],
                                    'amount':g['metric']['amount'],
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                   }
                                data_list5.append(row_dict)

                            except:
                              pass


df5=pd.DataFrame(data_list5)
df5

df5.to_csv('Top transaction data district wise .csv', index=False)

"""**#top transaction pincode wise**"""

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list6= []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/top/transaction/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)
                            # data_list5.append(data)
                            try:
                              for g in data['data']['pincodes']:
                                # print(g)
                                row_dict = {
                                    'States': state_dir,
                                    'pincode':g['entityName'],
                                    'count':g['metric']['count'],
                                    'amount':g['metric']['amount'],
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                   }
                                data_list6.append(row_dict)

                            except:
                              pass


df6=pd.DataFrame(data_list6)
df6

df6.to_csv('Top transaction data pincode wise .csv', index=False)

"""**#top user data district wise**"""

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list7= []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/top/user/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/top/user/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)
                            # data_list5.append(data)
                            try:
                              for g in data['data']['districts']:
                                # print(g)
                                row_dict = {
                                    'States': state_dir,
                                    'Registered_users':g['registeredUsers'],
                                    'district':g['name'],

                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                   }
                                data_list7.append(row_dict)

                            except:
                              pass


df7=pd.DataFrame(data_list7)
df7

df7.to_csv('top user data district wise .csv', index=False)

"""**#top user data pincode wise**"""

import os
import json
import pandas as pd

root_dir = (r'/content/pulse/data')

# Initialize empty list to hold dictionaries of data for each JSON file
data_list8= []

# Loop over all the state folders
for state_dir in os.listdir(os.path.join(root_dir, '/content/pulse/data/top/user/country/india/state')):
    state_path = os.path.join(root_dir, '/content/pulse/data/top/user/country/india/state', state_dir)
    if os.path.isdir(state_path):

        # Loop over all the year folders
        for year_dir in os.listdir(state_path):
            year_path = os.path.join(state_path, year_dir)
            if os.path.isdir(year_path):

                # Loop over all the JSON files (one for each quarter)
                for json_file in os.listdir(year_path):
                    if json_file.endswith('.json'):
                        with open(os.path.join(year_path, json_file)) as f:
                            data = json.load(f)
                            # data_list5.append(data)
                            try:
                              for g in data['data']['pincodes']:
                                # print(g)
                                row_dict = {
                                    'States': state_dir,
                                    'pincode':g['name'],
                                    'Registered_users':g['registeredUsers'],
                                    'Transaction_Year': year_dir,
                                    'Quarters': int(json_file.split('.')[0]),
                                   }
                                data_list8.append(row_dict)

                            except:
                              pass


df8=pd.DataFrame(data_list8)
df8

df8.to_csv('top user data pincode wise .csv', index=False)

"""**To find NULL values**"""

null_counts = df1.isnull().sum()
print(null_counts)

null_counts = df2.isnull().sum()
print(null_counts)

null_counts = df3.isnull().sum()
print(null_counts)

null_counts = df4.isnull().sum()
print(null_counts)

null_counts = df5.isnull().sum()
print(null_counts)

null_counts = df6.isnull().sum()
print(null_counts)

null_counts = df7.isnull().sum()
print(null_counts)

null_counts = df8.isnull().sum()
print(null_counts)

df1

df2

df3

df4

df5

df6

df7

df8

pip install mysql.connector

pip install sqlalchemy

pip install mysql

pip install mysql-connector-python

pip install PyMySQL

pip install mysql-connector-python pandas

pip install pysqlite3

import pymysql

mydb = pymysql.connect(host="localhost",user="root",password="Rakul1999")

mycursor=mydb.cursor()
mycursor.execute("CREATE DATABASE if not exists phonepe")
mycursor.execute("SHOW DATABASES")
mycursor.execute("USE phonepe")

def create_tables():

    import MySQLdb as mysql
    import pandas as pd
    import pymysql
    from sqlalchemy import create_engine



    mydb = mysql.connect(
        host="localhost",
        port=3306,
        user="root",
        password="Rakul@9360721393",
        database='phonepe',
        autocommit=True)

    mycursor=mydb.cursor()
    mycursor.execute("CREATE DATABASE if not exists phonepe")
    mycursor.execute("SHOW DATABASES")
    mycursor.execute("USE phonepe")

    #created table for aggregate transcation
    Agg_trans='''CREATE TABLE if not exists Agg_trans
                (States VARCHAR(255),
                Transaction_Year int,
                Quarters int,
                Transaction_Type TEXT,
                Transaction_Count int,
                Transaction_Amount TEXT);'''

    mycursor.execute(Agg_trans)


    #created table for aggregate users
    Agg_user=("CREATE TABLE if not exists agg_users ("
                 "States VARCHAR(255),"
                 "Transaction_Year int,"
                 "Quarters int,"
                 "brand VARCHAR(255),"
                 "Transaction_Count int",
                 "percentage int"
                 ")")
    mycursor.execute(Agg_user)

    #created table for Map transcation
    Map_trans = ("CREATE TABLE IF NOT EXISTS Map_trans ("
               "States VARCHAR(255),"
               "district VARCHAR(255),"
               "count INT,"
               "amount VARCHAR(255),"
               "Transaction_Year INT,"
               "Quarters INT,"
               ")")
    mycursor.execute(Map_trans)

    #created table for Map_users
    Map_users = ("CREATE TABLE IF NOT EXISTS Map_users ("
               "States VARCHAR(255),"
               "district VARCHAR(255),"
               "registered_users	INT,"
               "app_open INT,"
               "Transaction_Year INT,"
               "Quarters INT,"
               ")")
    mycursor.execute( Map_users)

    #created table for Top transaction data district wise
    Top_trans_ds = ("CREATE TABLE IF NOT EXISTS Top_trans_ds ("
               "States VARCHAR(255),"
               "district VARCHAR(255),"
               "count	 INT,"
               "amount VARCHAR(255),"
               "Transaction_Year INT,"
               "Quarters INT,"
               ")")
    mycursor.execute( Map_users)

    #created table for Top transaction data pincode wise
    Top_trans_pn = ("CREATE TABLE IF NOT EXISTS Top_trans_pn ("
               "States VARCHAR(255),"
               "users INT,"
               "name VARCHAR(255),"
               "Transaction_Year INT,"
               "Quarters INT,"
               ")")
    mycursor.execute(Top_trans_pn)


    #created table for Top transaction data users district wise
    Top_users_ds = ("CREATE TABLE IF NOT EXISTS Top_users_ds ("
               "States VARCHAR(255),"
               "users INT,"
               "name VARCHAR(255),"
               "Transaction_Year INT,"
               "Quarters INT,"
               ")")
    mycursor.execute(Top_users_ds)

    #created table for top users data pincode wise
    Top_users_pn = ("CREATE TABLE IF NOT EXISTS Top_users_pn ("
               "States VARCHAR(255),"
               "pincode INT",
               "users INT,"
               "name VARCHAR(255),"
               "Transaction_Year INT,"
               "Quarters INT,"
               ")")
    mycursor.execute(Top_users_pn)

create_tables()

import sqlite3

def create_tables():
    # Connect to the SQLite database (if it doesn't exist, it will be created)
    mydb = sqlite3.connect('phonepe.db')

    # Create a cursor object to execute SQL queries
    mycursor = mydb.cursor()

    # Create the table for aggregate transactions
    mycursor.execute('''CREATE TABLE IF NOT EXISTS Agg_trans
                       (States TEXT,
                        Transaction_Year INTEGER,
                        Quarters INTEGER,
                        Transaction_Type TEXT,
                        Transaction_Count INTEGER,
                        Transaction_Amount TEXT)''')

    # Create the table for aggregate users
    mycursor.execute('''CREATE TABLE IF NOT EXISTS agg_users (
                        States TEXT,
                        Transaction_Year INTEGER,
                        Quarters INTEGER,
                        brand TEXT,
                        Transaction_Count INTEGER,
                        percentage INTEGER)''')

    # Create the table for Map transaction
    mycursor.execute('''CREATE TABLE IF NOT EXISTS Map_trans (
                        States TEXT,
                        district TEXT,
                        count INTEGER,
                        amount TEXT,
                        Transaction_Year INTEGER,
                        Quarters INTEGER)''')

    # Create the table for Map users
    mycursor.execute('''CREATE TABLE IF NOT EXISTS Map_users (
                        States TEXT,
                        district TEXT,
                        registered_users INTEGER,
                        app_open INTEGER,
                        Transaction_Year INTEGER,
                        Quarters INTEGER)''')

    # Create the table for Top transaction data district wise
    mycursor.execute('''CREATE TABLE IF NOT EXISTS Top_trans_ds (
                        States TEXT,
                        district TEXT,
                        count INTEGER,
                        amount TEXT,
                        Transaction_Year INTEGER,
                        Quarters INTEGER)''')

    # Create the table for Top transaction data pincode wise
    mycursor.execute('''CREATE TABLE IF NOT EXISTS Top_trans_pn (
                        States TEXT,
                        users INTEGER,
                        name TEXT,
                        Transaction_Year INTEGER,
                        Quarters INTEGER)''')

    # Create the table for Top transaction data users district wise
    mycursor.execute('''CREATE TABLE IF NOT EXISTS Top_users_ds (
                        States TEXT,
                        users INTEGER,
                        name TEXT,
                        Transaction_Year INTEGER,
                        Quarters INTEGER)''')

    # Create the table for top users data pincode wise
    mycursor.execute('''CREATE TABLE IF NOT EXISTS Top_users_pn (
                        States TEXT,
                        pincode INTEGER,
                        users INTEGER,
                        name TEXT,
                        Transaction_Year INTEGER,
                        Quarters INTEGER)''')

    # Commit the changes and close the connection
    mydb.commit()
    mydb.close()

# Call the function to create the tables
create_tables()

import sqlite3

def create_tables():
    # Connect to the SQLite database (if it doesn't exist, it will be created)
    mydb = sqlite3.connect('phonepe.db')

    # Create a cursor object to execute SQL queries
    mycursor = mydb.cursor()

    # Create the table for aggregate transactions
    mycursor.execute('''CREATE TABLE IF NOT EXISTS Agg_trans
                       (States TEXT,
                        Transaction_Year INTEGER,
                        Quarters INTEGER,
                        Transaction_Type TEXT,
                        Transaction_Count INTEGER,
                        Transaction_Amount TEXT)''')

    # Commit the changes and close the connection
    mydb.commit()
    mydb.close()

# Call the function to create the tables
create_tables()

create_tables()

